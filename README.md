# Hi, I'm Navid Mirnouri

**Deep Learning Researcher & Engineer**  
Exploring the frontiers of **Large Language Models**, **Natural Language Processing**, and **Reinforcement Learning**.

---

### 🧠 About Me

I am a researcher with a deep interest in building intelligent systems that understand, reason, and interact with the world through language. My work spans across foundational and applied aspects of **LLMs**, **NLP**, and **deep RL**, focusing on alignment, generalization, and real-world deployment.

- 🧠 Focus: LLMs, Transformers, RLHF, Model Evaluation, Prompt Engineering  
- 🧪 Research interests: interpretability, alignment, multi-agent systems, societal simulations  
- 🛠️ Tools: PyTorch, Hugging Face, RLlib, LangChain, Weights & Biases  
- 🎯 Goal: Contribute to responsible AI research and advance understanding of intelligent behavior

---

### 📂 Featured Projects

#### 🧠 Simulating Society as a Neural Network
A conceptual and experimental framework modeling **societal systems as neural networks**, aiming to balance **fairness**, **efficiency**, and **meritocracy** using **deep learning and RL**.  
Keywords: Social Simulation, Policy Optimization, Ethics in AI  
📄 [Paper Draft (available on request)](https://github.com/navid72m)  
🔗 GitHub: [`navid72m/society-as-a-network`](https://github.com/navid72m)

#### 🤖 Real-Time LLMs on Embedded Devices
Research initiative exploring **model quantization**, **compression**, and **distillation** to deploy LLMs on edge hardware like **Jetson Orin Nano**.  
Focus: Efficient inference, low-latency deployment, hardware-aware design.  
🔗 GitHub: [`navid72m/llm-embedded`](https://github.com/navid72m)

#### 📈 Time Series & Forecasting Toolkit
End-to-end framework for visualizing, analyzing, and forecasting time series data using statistical and deep learning approaches.  
Tools: Prophet, ARIMA, LSTM  
🔗 GitHub: [`navid72m/time-series-lab`](https://github.com/navid72m)

#### 🔁 RLHF Experiments
Exploring how **human feedback** can guide the behavior of language models through reinforcement learning.  
Includes policy optimization experiments and reward model training.  
🔗 GitHub: [`navid72m/rlhf-lab`](https://github.com/navid72m)

---

### 🔬 Ongoing Research Directions

- 🌍 Language models in **multi-agent environments** for emergent behavior analysis  
- 🎲 **Game-theoretic approaches** to fairness and alignment in RL settings  
- 🧩 Investigating **hallucinations in LLMs** and developing robust evaluation metrics  
- 🧠 Preparing for a potential PhD on the intersection of **AI**, **philosophy**, and **decision theory**

---

### 📚 Learning & Reading

Currently reading:

- *"Hands-On Large Language Models"*  
- Papers on **mechanistic interpretability**  
- Stanford / DeepMind publications on **RLHF** and **AI alignment**

---

### 🔗 Connect with Me

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Navid%20Mirnouri-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/navid-mirnouri/)

---

<!-- Optional GitHub Stats (commented for minimalist style) -->
<!--
![Navid's GitHub Stats](https://github-readme-stats.vercel.app/api?username=navid72m&show_icons=true&hide=issues&count_private=true&theme=default)
-->

