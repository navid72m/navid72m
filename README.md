# Hi, I'm Navid Mirnouri

**Deep Learning Researcher & Engineer**  
Exploring the frontiers of **Large Language Models**, **Natural Language Processing**, and **Reinforcement Learning**.

---

### ğŸ§  About Me

I am a researcher with a deep interest in building intelligent systems that understand, reason, and interact with the world through language. My work spans across foundational and applied aspects of **LLMs**, **NLP**, and **deep RL**, focusing on alignment, generalization, and real-world deployment.

- ğŸ§  Focus: LLMs, Transformers, RLHF, Model Evaluation, Prompt Engineering  
- ğŸ§ª Research interests: interpretability, alignment, multi-agent systems, societal simulations  
- ğŸ› ï¸ Tools: PyTorch, Hugging Face, RLlib, LangChain, Weights & Biases  
- ğŸ¯ Goal: Contribute to responsible AI research and advance understanding of intelligent behavior

---

### ğŸ“‚ Featured Projects

#### ğŸ§  Simulating Society as a Neural Network
A conceptual and experimental framework modeling **societal systems as neural networks**, aiming to balance **fairness**, **efficiency**, and **meritocracy** using **deep learning and RL**.  
Keywords: Social Simulation, Policy Optimization, Ethics in AI  
ğŸ“„ [Paper Draft (available on request)](https://github.com/navid72m)  
ğŸ”— GitHub: [`navid72m/society-as-a-network`](https://github.com/navid72m)

#### ğŸ¤– Real-Time LLMs on Embedded Devices
Research initiative exploring **model quantization**, **compression**, and **distillation** to deploy LLMs on edge hardware like **Jetson Orin Nano**.  
Focus: Efficient inference, low-latency deployment, hardware-aware design.  
ğŸ”— GitHub: [`navid72m/llm-embedded`](https://github.com/navid72m)

#### ğŸ“ˆ Time Series & Forecasting Toolkit
End-to-end framework for visualizing, analyzing, and forecasting time series data using statistical and deep learning approaches.  
Tools: Prophet, ARIMA, LSTM  
ğŸ”— GitHub: [`navid72m/time-series-lab`](https://github.com/navid72m)

#### ğŸ” RLHF Experiments
Exploring how **human feedback** can guide the behavior of language models through reinforcement learning.  
Includes policy optimization experiments and reward model training.  
ğŸ”— GitHub: [`navid72m/rlhf-lab`](https://github.com/navid72m)

---

### ğŸ”¬ Ongoing Research Directions

- ğŸŒ Language models in **multi-agent environments** for emergent behavior analysis  
- ğŸ² **Game-theoretic approaches** to fairness and alignment in RL settings  
- ğŸ§© Investigating **hallucinations in LLMs** and developing robust evaluation metrics  
- ğŸ§  Preparing for a potential PhD on the intersection of **AI**, **philosophy**, and **decision theory**

---

### ğŸ“š Learning & Reading

Currently reading:

- *"Hands-On Large Language Models"*  
- Papers on **mechanistic interpretability**  
- Stanford / DeepMind publications on **RLHF** and **AI alignment**

---

### ğŸ”— Connect with Me

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Navid%20Mirnouri-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/navid-mirnouri/)

---

<!-- Optional GitHub Stats (commented for minimalist style) -->
<!--
![Navid's GitHub Stats](https://github-readme-stats.vercel.app/api?username=navid72m&show_icons=true&hide=issues&count_private=true&theme=default)
-->

